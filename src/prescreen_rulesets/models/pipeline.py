"""Data models for the post-rule-based prescreening pipeline.

After the 6-phase rule-based flow completes, two additional stages run:

  1. LLM Question Generator — produces follow-up questions based on the
     rule-based Q&A history.
  2. Prediction Module — consumes all Q&A pairs (rule-based + LLM-generated)
     and outputs differential diagnosis, department routing, and severity.

This module defines the data contracts that flow between these stages.
The actual implementations are external; the SDK only specifies the
input/output shapes here.
"""

from typing import Any, Literal

from pydantic import BaseModel, Field


# ---------------------------------------------------------------------------
# Shared Q&A representation
# ---------------------------------------------------------------------------

class QAPair(BaseModel):
    """A single question-answer record from any stage of prescreening.

    ``source`` distinguishes rule-based answers (which carry structured
    metadata like ``qid`` and ``phase``) from LLM-generated follow-ups
    (which are free-form strings).

    ``answer`` is typed as ``Any`` because rule-based answers vary widely:
    bool (ER yes/no), str (free text / single select), list[str] (multi
    select), dict (demographics / free_text_with_fields), or numeric
    (number_range).  LLM-generated answers are typically plain strings.
    """

    question: str
    answer: Any
    source: Literal["rule_based", "llm_generated"]

    # --- Fields populated only for rule-based Q&A ---
    qid: str | None = None
    question_type: str | None = None
    phase: int | None = None


# ---------------------------------------------------------------------------
# LLM Question Generator — output model
# ---------------------------------------------------------------------------
# The generator's *input* is ``list[QAPair]`` (the rule-based history).
# Its *output* is a simple list of question strings, wrapped in a model
# so consumers get validation and serialisation for free.

class GeneratedQuestions(BaseModel):
    """Output of the LLM question-generation stage.

    Each entry in ``questions`` is a natural-language question string that
    the LLM wants to ask the patient for additional diagnostic detail.
    """

    questions: list[str] = Field(
        default_factory=list,
        description="Follow-up questions generated by the LLM.",
    )


# ---------------------------------------------------------------------------
# Prediction Module — output models
# ---------------------------------------------------------------------------

class DiagnosisResult(BaseModel):
    """A single disease in the differential-diagnosis output.

    ``disease_id`` references a disease in ``v1/const/diseases.yaml``
    (e.g. "d001").  ``confidence`` is an optional model-assigned score
    in [0, 1]; its semantics depend on the prediction implementation.
    """

    disease_id: str
    confidence: float | None = None


class PredictionResult(BaseModel):
    """Full output of the prediction module.

    Mirrors the three prescreening goals:
      1. **diagnoses** — ranked differential-diagnosis list (disease IDs
         from ``v1/const/diseases.yaml``).
      2. **departments** — recommended department IDs (from
         ``v1/const/departments.yaml``).  Usually length 1, but a list
         to support multi-department referrals.
      3. **severity** — predicted severity-level ID (from
         ``v1/const/severity_levels.yaml``).
    """

    diagnoses: list[DiagnosisResult] = Field(
        default_factory=list,
        description="Ranked differential-diagnosis results.",
    )
    departments: list[str] = Field(
        default_factory=list,
        description="Predicted department IDs (e.g. ['dept004']).",
    )
    severity: str | None = Field(
        default=None,
        description="Predicted severity-level ID (e.g. 'sev002').",
    )


# ---------------------------------------------------------------------------
# Pipeline orchestrator models
# ---------------------------------------------------------------------------
# These models are used by PrescreenPipeline to communicate step results
# that span beyond the rule-based engine (LLM questioning + final result).


class LLMAnswer(BaseModel):
    """Input to submit_llm_answers(): one user answer to an LLM question."""

    question: str
    answer: str


class LLMQuestionsStep(BaseModel):
    """Pipeline step: present LLM-generated follow-up questions."""

    type: Literal["llm_questions"] = "llm_questions"
    questions: list[str]


class PipelineResult(BaseModel):
    """Pipeline step: final result with DDx, department, severity.

    Returned when the pipeline reaches the ``done`` stage — either after
    prediction runs or after early termination (ER redirect).

    ``history`` contains the full chronological Q&A trail for the session,
    including both rule-based and LLM-generated pairs.  Each entry carries
    ``qid``, ``question_type``, ``question`` (text), ``answer``, ``phase``,
    and ``source`` so consumers can reconstruct the entire conversation.
    """

    type: Literal["pipeline_result"] = "pipeline_result"
    departments: list[dict]
    severity: dict | None = None
    diagnoses: list[DiagnosisResult] = Field(default_factory=list)
    reason: str | None = None
    terminated_early: bool = False
    history: list[QAPair] = Field(
        default_factory=list,
        description="Full Q&A history for the session (rule-based + LLM).",
    )


# Union for pipeline step dispatching — callers match on step.type.
# Includes rule-based QuestionsStep (from session module) + pipeline-specific types.
# Defined here to avoid circular imports; consumers import via models/__init__.py.
from prescreen_rulesets.models.session import QuestionsStep  # noqa: E402

PipelineStep = QuestionsStep | LLMQuestionsStep | PipelineResult
