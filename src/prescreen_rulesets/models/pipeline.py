"""Data models for the post-rule-based prescreening pipeline.

After the 6-phase rule-based flow completes, two additional stages run:

  1. LLM Question Generator — produces follow-up questions based on the
     rule-based Q&A history.
  2. Prediction Module — consumes all Q&A pairs (rule-based + LLM-generated)
     and outputs differential diagnosis, department routing, and severity.

This module defines the data contracts that flow between these stages.
The actual implementations are external; the SDK only specifies the
input/output shapes here.
"""

from typing import Any, Literal

from pydantic import BaseModel, Field


# ---------------------------------------------------------------------------
# Shared Q&A representation
# ---------------------------------------------------------------------------

class QAPair(BaseModel):
    """A single question-answer record from any stage of prescreening.

    ``source`` distinguishes rule-based answers (which carry structured
    metadata like ``qid`` and ``phase``) from LLM-generated follow-ups
    (which are free-form strings).

    ``answer`` is typed as ``Any`` because rule-based answers vary widely:
    bool (ER yes/no), str (free text / single select), list[str] (multi
    select), dict (demographics / free_text_with_fields), or numeric
    (number_range).  LLM-generated answers are typically plain strings.
    """

    question: str
    answer: Any
    source: Literal["rule_based", "llm_generated"]

    # --- Fields populated only for rule-based Q&A ---
    qid: str | None = None
    question_type: str | None = None
    phase: int | None = None


# ---------------------------------------------------------------------------
# LLM Question Generator — output model
# ---------------------------------------------------------------------------
# The generator's *input* is ``list[QAPair]`` (the rule-based history).
# Its *output* is a simple list of question strings, wrapped in a model
# so consumers get validation and serialisation for free.

class GeneratedQuestions(BaseModel):
    """Output of the LLM question-generation stage.

    Each entry in ``questions`` is a natural-language question string that
    the LLM wants to ask the patient for additional diagnostic detail.
    """

    questions: list[str] = Field(
        default_factory=list,
        description="Follow-up questions generated by the LLM.",
    )


# ---------------------------------------------------------------------------
# Prediction Module — output models
# ---------------------------------------------------------------------------

class DiagnosisResult(BaseModel):
    """A single disease in the differential-diagnosis output.

    ``disease_id`` references a disease in ``v1/const/diseases.yaml``
    (e.g. "d001").  ``confidence`` is an optional model-assigned score
    in [0, 1]; its semantics depend on the prediction implementation.
    """

    disease_id: str
    confidence: float | None = None


class PredictionResult(BaseModel):
    """Full output of the prediction module.

    Mirrors the three prescreening goals:
      1. **diagnoses** — ranked differential-diagnosis list (disease IDs
         from ``v1/const/diseases.yaml``).
      2. **departments** — recommended department IDs (from
         ``v1/const/departments.yaml``).  Usually length 1, but a list
         to support multi-department referrals.
      3. **severity** — predicted severity-level ID (from
         ``v1/const/severity_levels.yaml``).
    """

    diagnoses: list[DiagnosisResult] = Field(
        default_factory=list,
        description="Ranked differential-diagnosis results.",
    )
    departments: list[str] = Field(
        default_factory=list,
        description="Predicted department IDs (e.g. ['dept004']).",
    )
    severity: str | None = Field(
        default=None,
        description="Predicted severity-level ID (e.g. 'sev002').",
    )
